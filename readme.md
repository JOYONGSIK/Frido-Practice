## NOTICE
> Reference: [Frido Github Link](https://github.com/davidhalladay/Frido)

- í˜„ì¬, Mac OSë¡œ ê°œë°œí•˜ì˜€ê¸°ì— ëª…ë ì–´ê°€ ë‹¤ë¥¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.
- port ë²ˆí˜¸, libraryëŠ” ì œ ì»´í“¨í„°ì— ë§ì¶° êµ¬í˜„ë˜ì–´ ìˆìŠµë‹ˆë‹¤. ì•Œë§ê²Œ ë³€ê²½í•´ì£¼ì‹œë©´ ê°ì‚¬í•˜ê² ìŠµë‹ˆë‹¤.   
- [Colab(Frido-Demo Colab ì‹¤ìŠµ)](https://colab.research.google.com/drive/1m4M6L0y0G97EQjDheeIgJBpfv4ZBJAVG?usp=sharing)ì—ì„œ Pre-trained ëª¨ë¸ì„ ì‚¬ìš©í•´ë³´ë ¤ê³  í–ˆìœ¼ë‚˜, OOMì˜ ë¬¸ì œë¡œ ì‚¬ìš©í•  ìˆ˜ ì—†ì—ˆìŠµë‹ˆë‹¤. 

<hr>

### Docker Part 
- <b>MacBook M1 ìœ¼ë¡œ ì¸í•´, DockerëŠ” êµ¬í˜„ë§Œ í•˜ê³  ê°€ìƒí™˜ê²½ì—ì„œ ì§„í–‰í–ˆìŠµë‹ˆë‹¤.</b>
```python
# MacBook M1ì´ë¯€ë¡œ device = torch.device('mps') ë¡œ ì§„í–‰ë©ë‹ˆë‹¤.
# pip install --pre torch torchvision torchaudio --extra-index-url https://download.pytorch.org/whl/nightly/cpu 
print(f"mps ì‚¬ìš© ê°€ëŠ¥ ì—¬ë¶€: {torch.backends.mps.is_available()}")
print(f"mps ì§€ì› í™˜ê²½ ì—¬ë¶€: {torch.backends.mps.is_built()}")
```

- ë²„ì „ ê´€ë¦¬ ë° ë°°í¬ë¥¼ í¸í•˜ê²Œ í•˜ê¸° ìœ„í•´ì„œ, docker êµ¬í˜„.<br>

- Docker Build *(default port 8010)*
    - ì˜¤ë¥˜ë‚˜ë©´, --recv-keys {Your Key} ê¸°ì…. Dockerfileì— ì£¼ì„ìœ¼ë¡œ ë‹¬ì•„ë†“ì•˜ìŠµë‹ˆë‹¤. <b>ì‹œê°„ì´ ì¡°ê¸ˆ ê±¸ë¦½ë‹ˆë‹¤.</b>

```
cd docker

docker build -t frido-practice:latest . 
or 
Check -> scripts/build :D 
```

- Docker Run
```
cd .. 

docker run --name frido-practice --gpus all -v $(pwd):/Frido-Practice -dit --ipc=host frido-practice:latest 
```

- Docker Start & Attach
```
docker start frido-practice 
docker attach frido-practice
```

<hr>

### ê°€ìƒí™˜ê²½ ìƒì„±

- Create venv Environment
```
python -m venv venv
source ./venv/bin/activate
```

- ```setup.py``` ì„¤ì¹˜
```
pip install -e "."
```


<hr>


### Datasets setup 
> ğŸ¶ Reference : [Frido Repo README](https://github.com/davidhalladay/Frido)

#### COCO-stuff 2017 
##### Standard split (Layout2I & Label2I), ì‚¬ìš© X 
- We follow [TwFA](https://openaccess.thecvf.com/content/CVPR2022/papers/Yang_Modeling_Image_Composition_for_Complex_Scene_Generation_CVPR_2022_paper.pdf) and [LAMA](https://openaccess.thecvf.com/content/ICCV2021/papers/Li_Image_Synthesis_From_Layout_With_Locality-Aware_Mask_Adaption_ICCV_2021_paper.pdf) to perform layout-to-image experiment on COCO-stuff 2017, which can be downloaded from [official COCO website](https://cocodataset.org/#download).
- Please create a folder name `2017` and collect the downloaded data and annotations as follows.
> Dataì˜ í¬ê¸°ê°€ ë„ˆë¬´ ì»¤ì„œ, coco-minitrainì„ ì‚¬ìš©í•  ê³„íšì…ë‹ˆë‹¤. [coco-minitrain github](https://github.com/giddyyupp/coco-minitrain)

   <details><summary>COCO-stuff 2017 split file structure</summary>

    ```
    >2017
    â”œâ”€â”€ annotations
    â”‚   â””â”€â”€ captions_val2017.json
    â”‚   â””â”€â”€ ...
    â””â”€â”€ val2017
        â””â”€â”€ 000000000872.jpg
        â””â”€â”€ ... 
 
    # ê¸°ì¡´ì˜ coco-Dataset ì €ì¥í•˜ëŠ”ë²•.
    mkdir 2017 
    cd coco 
    wget http://images.cocodataset.org/zips/val2017.zip 
    unzip val2017.zip  
    rm val2017.zip  
    ```
   </details>
